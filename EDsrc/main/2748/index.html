<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <title>Gemini Live Pro (v9 Stable)</title>
    <!--  ---idxq_2750---2025_11_27---00_34_27  qq66yy  lastGOODdesign pegel kein input laguage -->
    <script src="config.js"></script>
    <style>
        :root { --bg: #0b1120; --panel: #1e293b; --accent: #3b82f6; --text: #f1f5f9; --green: #10b981; --red: #ef4444; }
        body { font-family: 'Segoe UI', system-ui, sans-serif; background: var(--bg); color: var(--text); display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; overflow: hidden; }
        
        .panel { background: var(--panel); padding: 32px; border-radius: 24px; width: 100%; max-width: 600px; box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5); border: 1px solid #334155; }
        h1 { margin: 0; font-size: 1.8rem; font-weight: 800; text-align: center; color: var(--text); }
        .tagline { text-align: center; color: #64748b; font-size: 0.85rem; margin-bottom: 25px; font-family: monospace; }

        .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin-bottom: 24px; }
        .full { grid-column: span 2; }
        
        label { font-size: 0.7rem; color: #94a3b8; margin-bottom: 6px; display: block; text-transform: uppercase; font-weight: 700; }
        
        select, button { width: 100%; padding: 12px 16px; background: #0f172a; color: #f8fafc; border: 1px solid #334155; border-radius: 12px; font-size: 0.95rem; outline: none; transition: all 0.2s; }
        select:focus { border-color: var(--accent); }
        
        button { font-weight: 700; cursor: pointer; text-transform: uppercase; margin-top: 10px; border: none; }
        .btn-ready { background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); }
        .btn-connecting { background: #475569; cursor: wait; opacity: 0.8; }
        .btn-live { background: #ef4444; box-shadow: 0 0 15px rgba(239, 68, 68, 0.4); animation: pulse 2s infinite; }
        
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); } 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); } }

        #status { text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 20px; font-weight: 500; height: 24px; white-space: pre-wrap;}

        .meter-group { background: #0b1120; border-radius: 12px; padding: 12px; border: 1px solid #334155; margin-top: 8px; }
        .meter-row { display: flex; justify-content: space-between; margin-bottom: 6px; }
        .meter-label { font-size: 0.7rem; font-weight: 700; color: #64748b; }
        .track { width: 100%; height: 6px; background: #1e293b; border-radius: 3px; overflow: hidden; }
        .bar { height: 100%; width: 0%; transition: width 0.1s ease-out; border-radius: 3px; }
        #fillIn { background: var(--green); }
        #fillOut { background: var(--accent); }
    </style>
</head>
<body>

    <div class="panel">
        <h1>Gemini Live</h1>
        <div class="tagline">v9 ‚Ä¢ Buffered Audio ‚Ä¢ Stable GUI</div>
        
        <div class="grid">
            <div class="full">
                <label>KI Modell</label>
                <select id="modelSelect">
                    <option value="models/gemini-2.0-flash-exp">Gemini 2.0 Flash Exp</option>
                    <option value="models/gemini-2.0-flash-thinking-exp-1219">Gemini 2.0 Thinking</option>
                </select>
            </div>
            <div>
                <label>Zielsprache</label>
                <select id="targetLang">
                    <option value="English">Englisch üá∫üá∏</option>
                    <option value="German">Deutsch üá©üá™</option>
                    <option value="Spanish">Spanisch üá™üá∏</option>
                </select>
            </div>
            <div>
                 <label>Stimme</label>
                 <select id="voiceName">
                    <option value="Puck">Puck (M)</option>
                    <option value="Aoede">Aoede (W)</option>
                    <option value="Kore">Kore (W)</option>
                 </select>
            </div>
        </div>

        <div class="grid">
            <div class="full">
                <label>Mikrofon</label>
                <select id="micSelect"><option>Lade Ger√§te...</option></select>
                <div class="meter-group">
                    <div class="meter-row"><span class="meter-label">INPUT</span></div>
                    <div class="track"><div class="bar" id="fillIn"></div></div>
                </div>
            </div>

            <div class="full">
                <label>Lautsprecher</label>
                <select id="speakerSelect"><option>Standard</option></select>
                <div class="meter-group">
                    <div class="meter-row"><span class="meter-label">OUTPUT</span></div>
                    <div class="track"><div class="bar" id="fillOut"></div></div>
                </div>
            </div>
        </div>

        <button id="btnMain" class="btn-ready">Session Starten</button>
        <div id="status">Bereit.</div>
    </div>

<script>
// --- AUDIO WORKLET MIT BUFFER ---
// Sammelt ca 0.5 Sekunden Audio (8000 Samples bei 16k) bevor gesendet wird.
// Das verhindert "Too Many Requests" zuverl√§ssig.
const WORKLET_CODE = `
class BufferedProcessor extends AudioWorkletProcessor {
    constructor() {
        super();
        this.bufferSize = 8000; // 0.5 Sekunden Puffer
        this.buffer = new Float32Array(this.bufferSize);
        this.index = 0;
    }
    process(inputs, outputs) {
        const input = inputs[0];
        if (input && input.length > 0) {
            const channel = input[0];
            for (let i = 0; i < channel.length; i++) {
                this.buffer[this.index++] = channel[i];
                if (this.index >= this.bufferSize) {
                    this.port.postMessage(this.buffer);
                    this.index = 0;
                }
            }
        }
        return true;
    }
}
registerProcessor('buffered-processor', BufferedProcessor);
`;

const CONFIG = { host: "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent" };

let audioCtx = null, workletNode = null, micStream = null, micSource = null;
let inputAnalyser = null, outputAnalyser = null, ws = null;
let isConnected = false, nextStartTime = 0;

const ui = {
    mic: document.getElementById('micSelect'),
    spk: document.getElementById('speakerSelect'),
    model: document.getElementById('modelSelect'),
    lang: document.getElementById('targetLang'),
    voice: document.getElementById('voiceName'),
    btn: document.getElementById('btnMain'),
    status: document.getElementById('status'),
    fillIn: document.getElementById('fillIn'),
    fillOut: document.getElementById('fillOut')
};

// 1. INIT
async function init() {
    try {
        await navigator.mediaDevices.getUserMedia({ audio: true });
        const devices = await navigator.mediaDevices.enumerateDevices();
        ui.mic.innerHTML = ''; ui.spk.innerHTML = '';
        
        devices.forEach(d => {
            const opt = document.createElement('option');
            opt.value = d.deviceId;
            opt.text = d.label || d.kind;
            if(d.kind === 'audioinput') ui.mic.appendChild(opt);
            if(d.kind === 'audiooutput') ui.spk.appendChild(opt);
        });

        const vmIn = Array.from(ui.mic.options).find(o => o.text.includes("VoiceMeeter Out"));
        if(vmIn) ui.mic.value = vmIn.value;
        
        startMonitoring();
    } catch(e) { ui.status.innerText = "Mikrofon fehlt!"; }
}

// 2. MONITORING & ENGINE SETUP
async function startMonitoring() {
    if(audioCtx) await audioCtx.close();
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
    
    // Worklet laden
    const blob = new Blob([WORKLET_CODE], { type: 'application/javascript' });
    await audioCtx.audioWorklet.addModule(URL.createObjectURL(blob));

    try {
        micStream = await navigator.mediaDevices.getUserMedia({
            audio: { deviceId: { exact: ui.mic.value }, channelCount: 1, sampleRate: 16000 }
        });

        micSource = audioCtx.createMediaStreamSource(micStream);
        inputAnalyser = audioCtx.createAnalyser();
        inputAnalyser.fftSize = 256;
        
        outputAnalyser = audioCtx.createAnalyser();
        outputAnalyser.fftSize = 256;

        micSource.connect(inputAnalyser);
        outputAnalyser.connect(audioCtx.destination);
        
        drawMeters();
    } catch(e) {}
}
ui.mic.onchange = startMonitoring;

function drawMeters() {
    if(!audioCtx) return;
    const dIn = new Uint8Array(inputAnalyser.frequencyBinCount);
    inputAnalyser.getByteFrequencyData(dIn);
    ui.fillIn.style.width = Math.min(100, (dIn[0]/255)*300) + "%";

    const dOut = new Uint8Array(outputAnalyser.frequencyBinCount);
    outputAnalyser.getByteFrequencyData(dOut);
    ui.fillOut.style.width = Math.min(100, (dOut[0]/255)*300) + "%";
    
    requestAnimationFrame(drawMeters);
}

// 3. START / STOP
ui.btn.onclick = async () => {
    if (isConnected) return disconnect("Beendet");

    if(typeof CONFIG_API_KEY === 'undefined') return alert("config.js fehlt!");
    if(audioCtx.state === 'suspended') await audioCtx.resume();
    if(audioCtx.setSinkId && ui.spk.value) try { await audioCtx.setSinkId(ui.spk.value); } catch(e){}

    ui.btn.textContent = "Verbinde...";
    ui.btn.className = "btn-connecting";
    ui.btn.disabled = true;

    try { ws = new WebSocket(`${CONFIG.host}?key=${CONFIG_API_KEY}`); } catch(e) { return disconnect("WS Fehler"); }

    // Worklet erstellen
    workletNode = new AudioWorkletNode(audioCtx, 'buffered-processor');
    workletNode.port.onmessage = (e) => {
        // SICHERHEITS-CHECK: Nur senden, wenn wirklich OPEN
        if(!isConnected || !ws || ws.readyState !== WebSocket.OPEN) return;
        
        // Float32 -> Int16
        const float32 = e.data;
        const pcm = new Int16Array(float32.length);
        for(let i=0; i<float32.length; i++) {
            const s = Math.max(-1, Math.min(1, float32[i]));
            pcm[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        
        const b64 = btoa(String.fromCharCode(...new Uint8Array(pcm.buffer)));
        try {
            ws.send(JSON.stringify({ realtime_input: { media_chunks: [{ mime_type: "audio/pcm", data: b64 }] } }));
        } catch(err) { console.warn("Send failed", err); }
    };

    inputAnalyser.disconnect();
    inputAnalyser.connect(workletNode);
    workletNode.connect(audioCtx.destination); 

    ws.onopen = () => {
        // Handshake
        const setup = {
            setup: {
                model: ui.model.value,
                generation_config: { 
                    response_modalities: ["AUDIO"],
                    speech_config: { voice_config: { prebuilt_voice_config: { voice_name: ui.voice.value } } }
                },
                system_instruction: { parts: [{ text: `You are a translator. Translate to ${ui.lang.value}.` }] }
            }
        };
        ws.send(JSON.stringify(setup));
        
        // Stabilisierung
        setTimeout(() => {
            if(ws && ws.readyState === WebSocket.OPEN) {
                isConnected = true;
                ui.btn.textContent = "Verbindung Trennen";
                ui.btn.className = "btn-live";
                ui.btn.disabled = false;
                ui.status.innerHTML = "<span style='color:var(--green)'>‚óè ONLINE</span>";
                nextStartTime = audioCtx.currentTime;
            } else {
                if(!isConnected) disconnect("Verbindung abgelehnt");
            }
        }, 1000);
    };

    ws.onmessage = async (evt) => {
        const data = JSON.parse(evt.data instanceof Blob ? await evt.data.text() : evt.data);
        if(data.serverContent?.modelTurn?.parts) {
            data.serverContent.modelTurn.parts.forEach(p => {
                if(p.inlineData?.mimeType.startsWith('audio')) playAudio(p.inlineData.data);
            });
        }
    };

    ws.onclose = (e) => {
        console.log("Close Code:", e.code, e.reason);
        let msg = "Getrennt";
        if(e.code === 1011) msg = "‚ö†Ô∏è Quota Limit (Warte kurz)";
        disconnect(msg);
    };
    
    ws.onerror = (e) => { console.error(e); disconnect("Netzwerkfehler"); };
};

function disconnect(msg) {
    isConnected = false;
    if(ws) ws.close();
    if(workletNode) { workletNode.disconnect(); workletNode = null; }
    
    // Audio Routing Reset f√ºr Meter
    if(inputAnalyser && micSource) {
        inputAnalyser.disconnect();
        micSource.connect(inputAnalyser);
    }

    ui.btn.textContent = "Session Starten";
    ui.btn.className = "btn-ready";
    ui.btn.disabled = false;
    ui.status.innerText = msg;
    ui.status.style.color = msg.includes("‚ö†Ô∏è") ? "#ef4444" : "#64748b";
}

function playAudio(b64) {
    if(!audioCtx) return;
    const bin = atob(b64);
    const bytes = new Uint8Array(bin.length);
    const pcm = new Int16Array(bytes.buffer);
    const float = new Float32Array(pcm.length);
    for(let i=0; i<pcm.length; i++) float[i] = pcm[i] / 32768;

    const buf = audioCtx.createBuffer(1, float.length, 24000);
    buf.copyToChannel(float, 0);

    const src = audioCtx.createBufferSource();
    src.buffer = buf;
    if(outputAnalyser) src.connect(outputAnalyser);
    else src.connect(audioCtx.destination);

    const now = audioCtx.currentTime;
    if(nextStartTime < now) nextStartTime = now;
    src.start(nextStartTime);
    nextStartTime += buf.duration;
}

init();
</script>
</body>
</html>