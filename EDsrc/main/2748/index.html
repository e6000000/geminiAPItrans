<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <title>Gemini Live Core (Stable)</title>
    <script src="config.js"></script>
    <style>
        :root { --bg: #0b1120; --panel: #1e293b; --accent: #3b82f6; --text: #f1f5f9; --green: #10b981; --red: #ef4444; }
        body { font-family: 'Segoe UI', system-ui, sans-serif; background: var(--bg); color: var(--text); display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; margin: 0; overflow: hidden; }
        
        .panel { background: var(--panel); padding: 32px; border-radius: 24px; width: 100%; max-width: 650px; box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.5); border: 1px solid #334155; }
        h1 { margin: 0; font-size: 1.8rem; font-weight: 800; text-align: center; background: linear-gradient(to right, #60a5fa, #a78bfa); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
        .tagline { text-align: center; color: #64748b; font-size: 0.85rem; margin-bottom: 25px; font-family: monospace; }

        .grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; margin-bottom: 24px; }
        .full { grid-column: span 2; }
        
        label { font-size: 0.7rem; color: #94a3b8; margin-bottom: 6px; display: block; text-transform: uppercase; letter-spacing: 0.05em; font-weight: 700; }
        
        select, button { width: 100%; padding: 12px 16px; background: #0f172a; color: #f8fafc; border: 1px solid #334155; border-radius: 12px; font-size: 0.95rem; outline: none; transition: all 0.2s; }
        select:focus { border-color: var(--accent); }
        
        button { font-weight: 700; cursor: pointer; text-transform: uppercase; letter-spacing: 0.05em; margin-top: 10px; border: none; }
        
        /* Button States */
        .btn-ready { background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); box-shadow: 0 4px 12px rgba(37, 99, 235, 0.4); }
        .btn-connecting { background: #475569; cursor: wait; opacity: 0.8; }
        .btn-live { background: #ef4444; box-shadow: 0 4px 12px rgba(239, 68, 68, 0.4); animation: pulse 2s infinite; }
        
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); } 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); } }

        #status { text-align: center; font-size: 0.9rem; color: #64748b; margin-top: 20px; font-weight: 500; height: 24px; }

        .meter-group { background: #0b1120; border-radius: 12px; padding: 12px; border: 1px solid #334155; margin-top: 8px; }
        .meter-row { display: flex; justify-content: space-between; align-items: center; margin-bottom: 6px; }
        .meter-label { font-size: 0.7rem; font-weight: 700; color: #64748b; }
        .track { width: 100%; height: 6px; background: #1e293b; border-radius: 3px; overflow: hidden; }
        .bar { height: 100%; width: 0%; transition: width 0.08s ease-out; border-radius: 3px; }
        #fillIn { background: var(--green); }
        #fillOut { background: var(--accent); }
    </style>
</head>
<body>

    <div class="panel">
        <h1>Gemini Live Core</h1>
        <div class="tagline">AudioWorklet Engine ‚Ä¢ v6 Stable</div>
        
        <div class="grid">
            <div class="full">
                <label>KI Modell (Versuche wechseln bei Fehler)</label>
                <select id="modelSelect">
                    <option value="models/gemini-2.0-flash-exp">Gemini 2.0 Flash Exp (Standard)</option>
                    <option value="models/gemini-2.0-flash-thinking-exp-1219">Gemini 2.0 Thinking (Alternativ)</option>
                </select>
            </div>
            <div>
                <label>Zielsprache</label>
                <select id="targetLang">
                    <option value="English">Englisch üá∫üá∏</option>
                    <option value="German">Deutsch üá©üá™</option>
                    <option value="Spanish">Spanisch üá™üá∏</option>
                    <option value="Japanese">Japanisch üáØüáµ</option>
                </select>
            </div>
            <div>
                 <label>Stimme</label>
                 <select id="voiceName">
                    <option value="Puck">Puck (M)</option>
                    <option value="Aoede">Aoede (W)</option>
                    <option value="Charon">Charon (M)</option>
                    <option value="Kore">Kore (W)</option>
                    <option value="Fenrir">Fenrir (M)</option>
                 </select>
            </div>
        </div>

        <div class="grid">
            <div class="full">
                <label>Mikrofon</label>
                <select id="micSelect"><option>Lade Ger√§te...</option></select>
                <div class="meter-group">
                    <div class="meter-row"><span class="meter-label">MIC INPUT</span></div>
                    <div class="track"><div class="bar" id="fillIn"></div></div>
                </div>
            </div>

            <div class="full">
                <label>Lautsprecher</label>
                <select id="speakerSelect"><option>Standard</option></select>
                <div class="meter-group">
                    <div class="meter-row"><span class="meter-label">AI OUTPUT</span></div>
                    <div class="track"><div class="bar" id="fillOut"></div></div>
                </div>
            </div>
        </div>

        <button id="btnMain" class="btn-ready">Session Starten</button>
        <div id="status">Bereit.</div>
    </div>

<script>
// --- AUDIO WORKLET (INLINED) ---
const WORKLET_CODE = `
class PCMProcessor extends AudioWorkletProcessor {
    process(inputs, outputs) {
        const input = inputs[0];
        if (input && input.length > 0) {
            this.port.postMessage(input[0]);
        }
        return true;
    }
}
registerProcessor('pcm-processor', PCMProcessor);
`;

const CONFIG = { host: "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent" };

// Global State
let audioCtx = null;
let workletNode = null;
let micStream = null;
let micSource = null;
let inputAnalyser = null;
let outputAnalyser = null;
let ws = null;
let isConnected = false;
let nextStartTime = 0;

const ui = {
    mic: document.getElementById('micSelect'),
    spk: document.getElementById('speakerSelect'),
    model: document.getElementById('modelSelect'),
    lang: document.getElementById('targetLang'),
    voice: document.getElementById('voiceName'),
    btn: document.getElementById('btnMain'),
    status: document.getElementById('status'),
    fillIn: document.getElementById('fillIn'),
    fillOut: document.getElementById('fillOut')
};

// 1. INIT
async function init() {
    try {
        await navigator.mediaDevices.getUserMedia({ audio: true });
        const devices = await navigator.mediaDevices.enumerateDevices();
        ui.mic.innerHTML = ''; ui.spk.innerHTML = '';
        
        devices.forEach(d => {
            const opt = document.createElement('option');
            opt.value = d.deviceId;
            opt.text = d.label || d.kind;
            if(d.kind === 'audioinput') ui.mic.appendChild(opt);
            if(d.kind === 'audiooutput') ui.spk.appendChild(opt);
        });

        // Voicemeeter Auto-Select
        const vmIn = Array.from(ui.mic.options).find(o => o.text.includes("VoiceMeeter Out"));
        if(vmIn) ui.mic.value = vmIn.value;

        startMonitoring();
    } catch(e) { ui.status.innerText = "Mikrofon fehlt!"; ui.status.style.color = "red"; }
}

// 2. MONITORING
async function startMonitoring() {
    if(audioCtx) await audioCtx.close();
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000, latencyHint: 'interactive' });
    
    // Worklet laden
    const blob = new Blob([WORKLET_CODE], { type: 'application/javascript' });
    await audioCtx.audioWorklet.addModule(URL.createObjectURL(blob));

    try {
        micStream = await navigator.mediaDevices.getUserMedia({
            audio: { 
                deviceId: { exact: ui.mic.value },
                channelCount: 1, sampleRate: 16000,
                echoCancellation: false, noiseSuppression: false, autoGainControl: false 
            }
        });

        micSource = audioCtx.createMediaStreamSource(micStream);
        inputAnalyser = audioCtx.createAnalyser();
        inputAnalyser.fftSize = 256;
        micSource.connect(inputAnalyser);

        outputAnalyser = audioCtx.createAnalyser();
        outputAnalyser.fftSize = 256;
        outputAnalyser.connect(audioCtx.destination);

        drawMeters();
    } catch(e) { console.error(e); }
}
ui.mic.onchange = startMonitoring;

function drawMeters() {
    if(!audioCtx) return;
    if(inputAnalyser) {
        const d = new Uint8Array(inputAnalyser.frequencyBinCount);
        inputAnalyser.getByteFrequencyData(d);
        ui.fillIn.style.width = Math.min(100, (d[0]/255)*300) + "%";
    }
    if(outputAnalyser) {
        const d = new Uint8Array(outputAnalyser.frequencyBinCount);
        outputAnalyser.getByteFrequencyData(d);
        ui.fillOut.style.width = Math.min(100, (d[0]/255)*300) + "%";
    }
    requestAnimationFrame(drawMeters);
}

// 3. TOGGLE CONNECTION
ui.btn.onclick = async () => {
    if (isConnected) {
        disconnect("Beendet durch Benutzer");
        return;
    }

    if(typeof CONFIG_API_KEY === 'undefined') return alert("config.js fehlt!");
    if(audioCtx.state === 'suspended') await audioCtx.resume();
    
    if(audioCtx.setSinkId && ui.spk.value) {
        try { await audioCtx.setSinkId(ui.spk.value); } catch(e){}
    }

    // UI Update -> Connecting
    ui.btn.textContent = "Verbinde...";
    ui.btn.className = "btn-connecting";
    ui.btn.disabled = true;
    ui.status.innerText = "Handshake...";

    const url = `${CONFIG.host}?key=${CONFIG_API_KEY}`;
    
    try {
        ws = new WebSocket(url);
    } catch(e) { disconnect("WS Init Fehler"); return; }

    // Worklet verbinden
    workletNode = new AudioWorkletNode(audioCtx, 'pcm-processor');
    workletNode.port.onmessage = (e) => {
        if(!isConnected || !ws || ws.readyState !== WebSocket.OPEN) return;
        
        const float32 = e.data;
        const pcm = new Int16Array(float32.length);
        for(let i=0; i<float32.length; i++) {
            const s = Math.max(-1, Math.min(1, float32[i]));
            pcm[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        
        const b64 = btoa(String.fromCharCode(...new Uint8Array(pcm.buffer)));
        ws.send(JSON.stringify({ realtime_input: { media_chunks: [{ mime_type: "audio/pcm", data: b64 }] } }));
    };

    inputAnalyser.disconnect();
    inputAnalyser.connect(workletNode);
    workletNode.connect(audioCtx.destination);

    ws.onopen = () => {
        const setup = {
            setup: {
                model: ui.model.value,
                generation_config: { 
                    response_modalities: ["AUDIO"],
                    speech_config: { voice_config: { prebuilt_voice_config: { voice_name: ui.voice.value } } }
                },
                system_instruction: { 
                    parts: [{ text: `You are a translator. Translate input into ${ui.lang.value} immediately.` }] 
                }
            }
        };
        ws.send(JSON.stringify(setup));
        
        // Safety Check nach 1s
        setTimeout(() => {
            if(ws && ws.readyState === WebSocket.OPEN) {
                isConnected = true;
                ui.btn.textContent = "Verbindung Trennen";
                ui.btn.className = "btn-live";
                ui.btn.disabled = false;
                ui.status.innerHTML = "<span style='color:var(--green)'>‚óè ONLINE</span>";
                nextStartTime = audioCtx.currentTime;
            } else {
                // Falls WS schon wieder zu ist
                if(!isConnected) disconnect("Verbindung abgelehnt (Quota/Modell)");
            }
        }, 1000);
    };

    ws.onmessage = async (evt) => {
        const data = JSON.parse(evt.data instanceof Blob ? await evt.data.text() : evt.data);
        if(data.serverContent?.modelTurn?.parts) {
            data.serverContent.modelTurn.parts.forEach(p => {
                if(p.inlineData?.mimeType.startsWith('audio')) playAudio(p.inlineData.data);
            });
        }
    };

    ws.onclose = (e) => {
        console.log("Close Code:", e.code, e.reason);
        let msg = "Getrennt";
        if(e.code === 1011) msg = "‚ö†Ô∏è Modell √ºberlastet oder Limit";
        disconnect(msg);
    };
    
    ws.onerror = () => disconnect("Netzwerkfehler");
};

function disconnect(msg) {
    isConnected = false;
    
    if(ws) { ws.close(); ws = null; }
    if(workletNode) { workletNode.disconnect(); workletNode = null; }

    // Audio-Pfad resetten
    if(inputAnalyser && micSource) {
        inputAnalyser.disconnect(); // Trennt Worklet
        micSource.connect(inputAnalyser); // Verbindet wieder mit Source f√ºr Meter
    }

    ui.btn.textContent = "Session Starten";
    ui.btn.className = "btn-ready";
    ui.btn.disabled = false;
    ui.status.innerText = msg;
    ui.status.style.color = msg.includes("‚ö†Ô∏è") ? "#ef4444" : "#64748b";
}

function playAudio(b64) {
    if(!audioCtx) return;
    const bin = atob(b64);
    const bytes = new Uint8Array(bin.length);
    for(let i=0; i<bin.length; i++) bytes[i] = bin.charCodeAt(i);
    const pcm = new Int16Array(bytes.buffer);
    const float = new Float32Array(pcm.length);
    for(let i=0; i<pcm.length; i++) float[i] = pcm[i] / 32768;

    const buf = audioCtx.createBuffer(1, float.length, 24000);
    buf.copyToChannel(float, 0);

    const src = audioCtx.createBufferSource();
    src.buffer = buf;
    if(outputAnalyser) src.connect(outputAnalyser);
    else src.connect(audioCtx.destination);

    const now = audioCtx.currentTime;
    if(nextStartTime < now) nextStartTime = now;
    src.start(nextStartTime);
    nextStartTime += buf.duration;
}

init();
</script>
</body>
</html>